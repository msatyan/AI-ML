### Artificial Intelligence &amp; Machine Learning


### Artificial Intelligence (AI)
Machine seems like they have intelligence, though it is only an apparent intelligent behavior by machines. The AI systems mimics "cognitive" behavior like humans or other animals. It may do task such as learn things from its environment and solve problems. In computer science AI research is defined as the study of "intelligent agents"; any device that perceives its environment and takes actions that maximize its chance of success at some goal.  

Theoretically we can classify the **AI** into two, 
+ Weak AI (narrow AI)
+ Artificial General Intelligence (AGI)

##### Weak AI (narrow AI)
These are system with non-sentient machine intelligence, typically focused on a narrow task.  
IBM Watson, self-driving car, e-mail spam detection and the list goes on.

##### Artificial General Intelligence (AGI or Strong AI): (hypothetical)
AGI system has ability to apply intelligence to any problem and it could perform any task that a human is capable of. These systems are considered as smart as (or exceed) a typical human. At least for now such a system has not yet been developed. The Reinforcement Learning may take us one day to this level. 


### Machine Learning (ML)
Machine Learning is a field of computer science that gives computers the ability to learn without being explicitly programmed. Teaching computers how to learn from data to identify patterns then to make decisions rather than giving explicit programmed task. The ML makes machine learn like human by analyze thousands of examples then to build algorithms.  Then it constantly keeps fine tune the algorithms based on whether it has achieved its goals in the real life. Over a time, the program gets smarter and smarter. The reality is, there is no silver bullet in ML, no one algorithm works best for every problem. Based on the problem you may try different algorithms then test out and evaluate the performance and select the winner.

##### Major flavors of machine learning 
1. Supervised Learning
2. Unsupervised Learning
3. Reinforcement Learning


#### Supervised Learning
Supervised learning algorithms make predictions based on a set of examples (training data) that has used for training the system and produces an inferred function, which can be used for mapping new examples. For example, where you have input variables (x) and an output variable (y) and you use an algorithm to learn the mapping function from the input to the output. The training process continues until the model achieves a desired level of accuracy for the function.  
y = f(x)  

+ Classification
+ Regression
+ Anomaly detection.

##### List of Common Algorithms
+ Nearest Neighbor
+ Naive Bayes
+ Decision Trees
+ Linear Regression
+ Support Vector Machines (SVM)
+ Neural Networks


#### Unsupervised learning
In unsupervised learning, data points have no labels associated with them. Instead, the goal of an unsupervised learning algorithm is to organize the data in some way or to describe its structure. It is widely used for segmenting customers in different groups for specific intervention etc.

##### List of Common Algorithms
+ k-means clustering, 
+ Association Rules
+ Apriori algorithm



#### Reinforcement learning
In reinforcement learning, the machine (agent) is exposed to an environment where it trains itself continually using trial and error (action and reward) indicating how good the decision was. Based on this, the algorithm modifies its strategy to achieve the highest reward.
Reinforcement learning is common in IoT and robotics, where the set of sensor readings at one point in time is a data point, and the algorithm must choose the robot's next action. 

##### List of Common Algorithms
+ Q-Learning
+ Temporal Difference (TD)
+ Deep Adversarial Networks

#### Common Machine Learning tasks
+ Regression
+ Classification
+ Clustering
+ Feature Selection
+ Feature Extraction

##### Regression 
Regression is the supervised learning task for modeling and predicting continuous, numeric variables. Examples include predicting real-estate prices, stock price movements, or student test scores

##### Classification
Classification is the supervised learning task for modeling and predicting categorical variables. Eg: email spam, financial fraud, or student letter grades.

##### Clustering
Clustering is an unsupervised learning task for finding natural groupings of observations (i.e. clusters) based on the inherent structure within your dataset.

##### Feature Selection
Feature selection is the process of selecting a subset of relevant features for use in model construction.

##### Feature extraction
Feature extraction you build a new set of features from the original feature set, i.e. reduce dimensionality by (linear or non- linear) projection of N dimensional vector onto X dimensional vector, where X < N.



#### Some of the fundamental algorithms used by ML 
+ Random Forest (2001: Leo Breiman)
(used for both classification and regression)
+ Gradient Boosting Machines (Late 90s: Jerome H. Friedman and Leo Breiman )
+ Support Vector Machines (1963 by Vladimir Vapnik and Alexey Chervonenkis)
+ Neural Networks (1950s)
Computational model for neural networks based on mathematics and algorithms by Warren McCulloch and Walter Pitts (1943).  
1949 Donald Hebb created a learning hypothesis based on the mechanism of neural plasticity that is now known as Hebbian learning (unsupervised learning rule.)  
Farley and Clark (1954) first used computational machines, then called "calculators", to simulate a Hebbian network.
